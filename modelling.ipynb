{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/davide/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import softmax, relu\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "debug = False\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39798, 10168)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_hdf(\"data/train.hdf5\")\n",
    "df_test = pd.read_hdf(\"data/test.hdf5\")\n",
    "\n",
    "len(df_train), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(no    14979\n",
       " da    14305\n",
       " sv    10514\n",
       " Name: label, dtype: int64,\n",
       " no    3887\n",
       " da    3637\n",
       " sv    2644\n",
       " Name: label, dtype: int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if debug:\n",
    "    df_train = shuffle_df(df_train)\n",
    "    df_test = shuffle_df(df_test)\n",
    "    df_train = df_train.iloc[:int(len(df_train)/ 4)]\n",
    "    df_test = df_test.iloc[:int(len(df_train)/ 4)]\n",
    "    \n",
    "df_train[\"label\"].value_counts(), df_test[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(line):\n",
    "    words = nltk.word_tokenize(line)\n",
    "    tokens = [word for word in words if word.isalnum()]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"data\"] = df_train[\"data\"].apply(tokenize)\n",
    "df_test[\"data\"] = df_test[\"data\"].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['da' 'no' 'sv']\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_train[\"label\"].values)\n",
    "print(le.classes_)\n",
    "df_train[\"y\"] = le.transform(df_train[\"label\"])\n",
    "df_test[\"y\"] = le.transform(df_test[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[grønlands, politik]</td>\n",
       "      <td>da</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[ooa, var, en, åben, bevægelse, med, et, lands...</td>\n",
       "      <td>da</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[i, august, samlede, to, store, atomkraftmarch...</td>\n",
       "      <td>da</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[den]</td>\n",
       "      <td>da</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[november, begyndte, oaa, som, skulle, vise, a...</td>\n",
       "      <td>da</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49944</th>\n",
       "      <td>[i, en, del, tilfeller, ble, det, oppnådd, ell...</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49945</th>\n",
       "      <td>[prosessen, for, sosiale, og, politiske, endri...</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49948</th>\n",
       "      <td>[begrepet, henspiller, ikke, på, en, bestemt, ...</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49949</th>\n",
       "      <td>[den]</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49951</th>\n",
       "      <td>[januar, da, alexander, dubček, kom, til, makt...</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10168 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    data label  y\n",
       "0                                   [grønlands, politik]    da  0\n",
       "7      [ooa, var, en, åben, bevægelse, med, et, lands...    da  0\n",
       "11     [i, august, samlede, to, store, atomkraftmarch...    da  0\n",
       "15                                                 [den]    da  0\n",
       "19     [november, begyndte, oaa, som, skulle, vise, a...    da  0\n",
       "...                                                  ...   ... ..\n",
       "49944  [i, en, del, tilfeller, ble, det, oppnådd, ell...    no  1\n",
       "49945  [prosessen, for, sosiale, og, politiske, endri...    no  1\n",
       "49948  [begrepet, henspiller, ikke, på, en, bestemt, ...    no  1\n",
       "49949                                              [den]    no  1\n",
       "49951  [januar, da, alexander, dubček, kom, til, makt...    no  1\n",
       "\n",
       "[10168 rows x 3 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary\n",
    "vocab = set()\n",
    "for line in df_train[\"data\"].values:\n",
    "    vocab.update(set(line))\n",
    "for line in df_test[\"data\"].values:\n",
    "    vocab.update(set(line))\n",
    "\n",
    "# Build a word to index lookup\n",
    "w2i = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109018"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangModel(\n",
      "  (embeddings): Embedding(109018, 32)\n",
      "  (rnn_1): LSTM(32, 100, num_layers=2, bidirectional=True)\n",
      "  (l_out): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=200, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Linear(in_features=200, out_features=64, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Linear(in_features=64, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LangModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(LangModel, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, 32)\n",
    "\n",
    "        self.rnn_1 = nn.LSTM(\n",
    "            input_size=32,\n",
    "            hidden_size=100,\n",
    "            num_layers=2,\n",
    "            bidirectional=True,\n",
    "            batch_first=False,\n",
    "        )\n",
    "\n",
    "        self.l_out = nn.Sequential(\n",
    "            nn.Linear(400, 200),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(200, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(64, 3),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = {}\n",
    "        # get embeddings\n",
    "        x = self.embeddings(x)\n",
    "\n",
    "        # output, hidden state\n",
    "        x, _ = self.rnn_1(x)\n",
    "\n",
    "        x = torch.cat((torch.mean(x, dim=0), torch.max(x, dim=0)[0]), dim=1)\n",
    "\n",
    "        # classify\n",
    "        out[\"out\"] = softmax(self.l_out(x), dim=1)\n",
    "        return out\n",
    "\n",
    "net = LangModel(len(w2i))\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_batch(df_batch):\n",
    "    # Get indices\n",
    "    inputs = [[w2i[token] for token in row] for y, row in df_batch[\"data\"].iteritems()]\n",
    "    \n",
    "    # Get the longest row\n",
    "    longest = max([len(row) for row in inputs])\n",
    "\n",
    "    # Make the rows equal size\n",
    "    new_inputs = np.empty([len(df_batch), longest])\n",
    "    for i in range(len(df_batch)):\n",
    "        if len(inputs[i]) == 0:        \n",
    "            new_inputs[i] = np.pad(inputs[i], (0, longest - len(inputs[i])), 'constant', constant_values=0)\n",
    "        else:\n",
    "            new_inputs[i] = np.pad(inputs[i], (0, longest - len(inputs[i])), 'wrap')\n",
    "\n",
    "    inp = torch.Tensor(new_inputs.T).long()\n",
    "    \n",
    "    return inp\n",
    "\n",
    "# Shuffle the rows of a pandas data frame\n",
    "def shuffle_df(df):\n",
    "    return df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Return an iterable over mini-batches\n",
    "def batchify(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3268095987411487"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_test[\"y\"], np.random.randint(3, size=len(df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(net, df_test, batch_size, epoch):\n",
    "    batches = batchify(df_test, batch_size)\n",
    "    net.eval()\n",
    "    loss = []\n",
    "    out = []\n",
    "    for df_batch in batches:\n",
    "        inp = create_input_batch(df_batch)\n",
    "        labels = torch.Tensor(df_batch['y'].values).long()\n",
    "        output = net(inp)\n",
    "        batch_loss = criterion(output['out'], labels)\n",
    "        loss.append(batch_loss.item())\n",
    "        _, pred = torch.max(output['out'].detach(), 1)\n",
    "        out.extend(pred)\n",
    "        \n",
    "    mean_loss = np.mean(loss)\n",
    "    accuracy = accuracy_score(df_test['y'], out)\n",
    "        \n",
    "    print(f\"Validation loss after {epoch} epoch: {mean_loss}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    \n",
    "    return mean_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_model(net, experiment, accuracy):\n",
    "    model_path = os.path.join(\"app\", \"lang_model\", \"data\", \"models\", experiment)\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "        \n",
    "    path = os.path.join(model_path, f\"{accuracy}_.pt\")\n",
    "    \n",
    "    current_best = list(filter(lambda x: x.endswith(\".pt\"), os.listdir(model_path)))\n",
    "    if len(current_best) == 0:\n",
    "        torch.save(net.state_dict(), path)\n",
    "        return True\n",
    "        \n",
    "    current_best_acc = float(current_best[0].split(\"_\")[0])\n",
    "    if accuracy > current_best_acc:\n",
    "        torch.save(net.state_dict(), path)\n",
    "        os.remove(os.path.join(model_path, current_best[0]))\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Validation loss after 0 epoch: 1.0981844984568083\n",
      "Accuracy: 0.38227773406766324\n",
      "39798\n",
      "Iteration:0/711 loss: 1.0944849252700806\n",
      "Iteration:60/711 loss: 0.9395195841789246\n",
      "Iteration:120/711 loss: 0.8047592043876648\n",
      "Iteration:180/711 loss: 0.7978276014328003\n",
      "Iteration:240/711 loss: 0.7565897703170776\n",
      "Iteration:300/711 loss: 0.6723564267158508\n",
      "Iteration:360/711 loss: 0.7508235573768616\n",
      "Iteration:420/711 loss: 0.7848092913627625\n",
      "Iteration:480/711 loss: 0.7111197710037231\n",
      "Iteration:540/711 loss: 0.7603636980056763\n",
      "Iteration:600/711 loss: 0.7182220816612244\n",
      "Iteration:660/711 loss: 0.7094685435295105\n",
      "Validation loss after 0 epoch: 0.7192801839702732\n",
      "Accuracy: 0.8258261211644374\n",
      "New best model saved.\n",
      "Epoch: 1\n",
      "39798\n",
      "Iteration:0/711 loss: 0.6990412473678589\n",
      "Iteration:60/711 loss: 0.6683153510093689\n",
      "Iteration:120/711 loss: 0.6749995350837708\n",
      "Iteration:180/711 loss: 0.7053447961807251\n",
      "Iteration:240/711 loss: 0.642067551612854\n",
      "Iteration:300/711 loss: 0.7189406156539917\n",
      "Iteration:360/711 loss: 0.7142041325569153\n",
      "Iteration:420/711 loss: 0.7481035590171814\n",
      "Iteration:480/711 loss: 0.6883485913276672\n",
      "Iteration:540/711 loss: 0.6697916984558105\n",
      "Iteration:600/711 loss: 0.7388470768928528\n",
      "Iteration:660/711 loss: 0.6989148855209351\n",
      "Validation loss after 1 epoch: 0.6866109394110166\n",
      "Accuracy: 0.8595594020456334\n",
      "New best model saved.\n",
      "Epoch: 2\n",
      "39798\n",
      "Iteration:0/711 loss: 0.6311736702919006\n",
      "Iteration:60/711 loss: 0.6564345359802246\n",
      "Iteration:120/711 loss: 0.6918448209762573\n",
      "Iteration:180/711 loss: 0.6721717715263367\n",
      "Iteration:240/711 loss: 0.6866825819015503\n",
      "Iteration:300/711 loss: 0.6634198427200317\n",
      "Iteration:360/711 loss: 0.585163414478302\n",
      "Iteration:420/711 loss: 0.6136035323143005\n",
      "Iteration:480/711 loss: 0.6452187895774841\n",
      "Iteration:540/711 loss: 0.6636020541191101\n",
      "Iteration:600/711 loss: 0.6273447871208191\n",
      "Iteration:660/711 loss: 0.6870560050010681\n",
      "Validation loss after 2 epoch: 0.6847918262848487\n",
      "Accuracy: 0.8577891424075531\n",
      "Epoch: 3\n",
      "39798\n",
      "Iteration:0/711 loss: 0.6451030373573303\n",
      "Iteration:60/711 loss: 0.5925691723823547\n",
      "Iteration:120/711 loss: 0.6017982363700867\n",
      "Iteration:180/711 loss: 0.6289454102516174\n",
      "Iteration:240/711 loss: 0.6168168783187866\n",
      "Iteration:300/711 loss: 0.609253466129303\n",
      "Iteration:360/711 loss: 0.732067883014679\n",
      "Iteration:420/711 loss: 0.6018199920654297\n",
      "Iteration:480/711 loss: 0.6017095446586609\n",
      "Iteration:540/711 loss: 0.6445270776748657\n",
      "Iteration:600/711 loss: 0.6387486457824707\n",
      "Iteration:660/711 loss: 0.6213627457618713\n",
      "Validation loss after 3 epoch: 0.6682438572029491\n",
      "Accuracy: 0.8802124311565697\n",
      "New best model saved.\n",
      "Epoch: 4\n",
      "39798\n",
      "Iteration:0/711 loss: 0.6320366263389587\n",
      "Iteration:60/711 loss: 0.6402157545089722\n",
      "Iteration:120/711 loss: 0.6385275721549988\n",
      "Iteration:180/711 loss: 0.6184223890304565\n",
      "Iteration:240/711 loss: 0.6178992986679077\n",
      "Iteration:300/711 loss: 0.6226447224617004\n",
      "Iteration:360/711 loss: 0.59795743227005\n",
      "Iteration:420/711 loss: 0.6621138453483582\n",
      "Iteration:480/711 loss: 0.5875139236450195\n",
      "Iteration:540/711 loss: 0.562534511089325\n",
      "Iteration:600/711 loss: 0.6396967768669128\n",
      "Iteration:660/711 loss: 0.6373656392097473\n",
      "Validation loss after 4 epoch: 0.6824211687832088\n",
      "Accuracy: 0.8649685287175453\n",
      "Epoch: 5\n",
      "39798\n",
      "Iteration:0/711 loss: 0.6254719495773315\n",
      "Iteration:60/711 loss: 0.6318926811218262\n",
      "Iteration:120/711 loss: 0.6054458618164062\n",
      "Iteration:180/711 loss: 0.6390511393547058\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-8148ee08df55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m60\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lan_wire/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lan_wire/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 56\n",
    "batches = batchify(df_train, batch_size)\n",
    "length = sum(1 for x in batches)\n",
    "experiment = \"LSTM\"\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    if epoch == 0:\n",
    "        validate(net, df_test, batch_size, epoch)\n",
    "    net.train()\n",
    "    shuffled_df = shuffle_df(df_train)\n",
    "    print(len(shuffled_df))\n",
    "    counter = 0\n",
    "    batches = batchify(shuffled_df, batch_size)\n",
    "    \n",
    "    for df_batch in batches:\n",
    "        \n",
    "        inp = create_input_batch(df_batch)\n",
    "        labels = torch.Tensor(df_batch['y'].values).long()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = net(inp)\n",
    "\n",
    "        batch_loss = criterion(output['out'], labels)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        if(counter % 60 == 0):\n",
    "            print(f\"Iteration:{counter}/{length} loss: {batch_loss.item()}\")\n",
    "            \n",
    "        \n",
    "        counter += 1\n",
    "    _, accuracy = validate(net, df_test, batch_size, epoch)\n",
    "    saved = save_best_model(net, experiment, accuracy)\n",
    "    if saved:\n",
    "        print(f\"New best model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('app/lang_model/data/vocab/vocab.data', 'wb') as filehandle:\n",
    "    # store the data as binary data stream\n",
    "    pickle.dump(vocab, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "This notebook contains code for training an LSTM deep neural network for classifying danish, norwegian and swedish language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/david/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import softmax, relu\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set this to true, if testing the pipeline\n",
    "debug = False\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64966, 16190)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_hdf(\"app/lang_model/data/train.hdf5\")\n",
    "df_test = pd.read_hdf(\"app/lang_model/data/test.hdf5\")\n",
    "\n",
    "len(df_train), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(da    26153\n",
       " no    22866\n",
       " sv    15947\n",
       " Name: label, dtype: int64,\n",
       " da    6425\n",
       " no    5839\n",
       " sv    3926\n",
       " Name: label, dtype: int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For debugging purposes use only part of the data\n",
    "if debug:\n",
    "    df_train = shuffle_df(df_train)\n",
    "    df_test = shuffle_df(df_test)\n",
    "    df_train = df_train.iloc[:int(len(df_train)/ 4)]\n",
    "    df_test = df_test.iloc[:int(len(df_train)/ 4)]\n",
    "    \n",
    "df_train[\"label\"].value_counts(), df_test[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(line):\n",
    "    words = nltk.word_tokenize(line)\n",
    "    tokens = [word for word in words if word.isalnum()]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"data\"] = df_train[\"data\"].apply(tokenize)\n",
    "df_test[\"data\"] = df_test[\"data\"].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['da' 'no' 'sv']\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_train[\"label\"].values)\n",
    "print(le.classes_)\n",
    "df_train[\"y\"] = le.transform(df_train[\"label\"])\n",
    "df_test[\"y\"] = le.transform(df_test[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[på, næste, niveau, er, landet, inddelt, i, di...</td>\n",
       "      <td>da</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[landsdel, er, i, forbindelse, med, folketings...</td>\n",
       "      <td>da</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[den, omfatter, østjyllands, storkreds, nordjy...</td>\n",
       "      <td>da</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ved, næste, folketingsvalg, vil, den, fordeli...</td>\n",
       "      <td>da</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[fysiske, egenskaber, beskrives, ofte, som, ob...</td>\n",
       "      <td>da</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81123</th>\n",
       "      <td>[regional, patterns, of, diversity, and, estim...</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81125</th>\n",
       "      <td>[and, gaston]</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81137</th>\n",
       "      <td>[duken, besto, tidligere, av, sammensydde, rei...</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81143</th>\n",
       "      <td>[lávvu, forveksles, ofte, med, bealljegoahti]</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81147</th>\n",
       "      <td>[mens, lávvu, tradisjonelt, har, vært, brukt, ...</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16190 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    data label  y\n",
       "1      [på, næste, niveau, er, landet, inddelt, i, di...    da  0\n",
       "2      [landsdel, er, i, forbindelse, med, folketings...    da  0\n",
       "3      [den, omfatter, østjyllands, storkreds, nordjy...    da  0\n",
       "4      [ved, næste, folketingsvalg, vil, den, fordeli...    da  0\n",
       "7      [fysiske, egenskaber, beskrives, ofte, som, ob...    da  0\n",
       "...                                                  ...   ... ..\n",
       "81123  [regional, patterns, of, diversity, and, estim...    no  1\n",
       "81125                                      [and, gaston]    no  1\n",
       "81137  [duken, besto, tidligere, av, sammensydde, rei...    no  1\n",
       "81143      [lávvu, forveksles, ofte, med, bealljegoahti]    no  1\n",
       "81147  [mens, lávvu, tradisjonelt, har, vært, brukt, ...    no  1\n",
       "\n",
       "[16190 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary\n",
    "vocab = set()\n",
    "for line in df_train[\"data\"].values:\n",
    "    vocab.update(set(line))\n",
    "for line in df_test[\"data\"].values:\n",
    "    vocab.update(set(line))\n",
    "\n",
    "# Build a word to index lookup\n",
    "w2i = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('app/lang_model/data/vocab/vocab_1.data', 'wb') as filehandle:\n",
    "    # store the data as binary data stream\n",
    "    pickle.dump(vocab, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164657"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangModel(\n",
      "  (embeddings): Embedding(164657, 64)\n",
      "  (rnn_1): LSTM(64, 100, num_layers=2, bidirectional=True)\n",
      "  (l_out): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=200, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Linear(in_features=200, out_features=64, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Linear(in_features=64, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LangModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(LangModel, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, 64)\n",
    "\n",
    "        self.rnn_1 = nn.LSTM(\n",
    "            input_size=64,\n",
    "            hidden_size=100,\n",
    "            num_layers=2,\n",
    "            bidirectional=True,\n",
    "            batch_first=False,\n",
    "        )\n",
    "\n",
    "        self.l_out = nn.Sequential(\n",
    "            nn.Linear(400, 200),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(200, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(64, 3),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = {}\n",
    "        # get embeddings\n",
    "        x = self.embeddings(x)\n",
    "\n",
    "        # output, hidden state\n",
    "        x, _ = self.rnn_1(x)\n",
    "\n",
    "        x = torch.cat((torch.mean(x, dim=0), torch.max(x, dim=0)[0]), dim=1)\n",
    "\n",
    "        # classify\n",
    "        out[\"out\"] = softmax(self.l_out(x), dim=1)\n",
    "        return out\n",
    "\n",
    "net = LangModel(len(w2i)).to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_batch(df_batch):\n",
    "    # Get indices\n",
    "    inputs = [[w2i[token] for token in row] for y, row in df_batch[\"data\"].iteritems()]\n",
    "    \n",
    "    # Get the longest row\n",
    "    longest = max([len(row) for row in inputs])\n",
    "\n",
    "    # Make the rows equal size\n",
    "    new_inputs = np.empty([len(df_batch), longest])\n",
    "    for i in range(len(df_batch)):\n",
    "        if len(inputs[i]) == 0:        \n",
    "            new_inputs[i] = np.pad(inputs[i], (0, longest - len(inputs[i])), 'constant', constant_values=0)\n",
    "        else:\n",
    "            new_inputs[i] = np.pad(inputs[i], (0, longest - len(inputs[i])), 'wrap')\n",
    "\n",
    "    inp = torch.Tensor(new_inputs.T).to(device).long()\n",
    "    \n",
    "    return inp\n",
    "\n",
    "# Shuffle the rows of a pandas data frame\n",
    "def shuffle_df(df):\n",
    "    return df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Return an iterable over mini-batches\n",
    "def batchify(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3339098208770846"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_test[\"y\"], np.random.randint(3, size=len(df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(net, df_test, batch_size, epoch):\n",
    "    batches = batchify(df_test, batch_size)\n",
    "    net.eval()\n",
    "    loss = []\n",
    "    out = []\n",
    "    for df_batch in batches:\n",
    "        inp = create_input_batch(df_batch)\n",
    "        labels = torch.Tensor(df_batch['y'].values).to(device).long()\n",
    "        output = net(inp)\n",
    "        batch_loss = criterion(output['out'], labels)\n",
    "        loss.append(batch_loss.item())\n",
    "        _, pred = torch.max(output['out'].detach().cpu(), 1)\n",
    "        out.extend(pred)\n",
    "        \n",
    "    mean_loss = np.mean(loss)\n",
    "    accuracy = accuracy_score(df_test['y'], out)\n",
    "        \n",
    "    print(f\"Validation loss after {epoch} epoch: {mean_loss}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    \n",
    "    return mean_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_model(net, experiment, accuracy):\n",
    "    model_path = os.path.join(\"app\", \"lang_model\", \"data\", \"models\", experiment)\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "        \n",
    "    path = os.path.join(model_path, f\"{accuracy}_.pt\")\n",
    "    \n",
    "    current_best = list(filter(lambda x: x.endswith(\".pt\"), os.listdir(model_path)))\n",
    "    if len(current_best) == 0:\n",
    "        torch.save(net.state_dict(), path)\n",
    "        return True\n",
    "        \n",
    "    current_best_acc = float(current_best[0].split(\"_\")[0])\n",
    "    if accuracy > current_best_acc:\n",
    "        torch.save(net.state_dict(), path)\n",
    "        os.remove(os.path.join(model_path, current_best[0]))\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Validation loss after 0 epoch: 1.0996856360965306\n",
      "Accuracy: 0.3554663372452131\n",
      "64966\n",
      "Iteration:0/903 loss: 1.121610403060913\n",
      "Iteration:60/903 loss: 0.8345963954925537\n",
      "Iteration:120/903 loss: 0.80738365650177\n",
      "Iteration:180/903 loss: 0.7406399846076965\n",
      "Iteration:240/903 loss: 0.7735495567321777\n",
      "Iteration:300/903 loss: 0.8141270279884338\n",
      "Iteration:360/903 loss: 0.7172715067863464\n",
      "Iteration:420/903 loss: 0.7312549948692322\n",
      "Iteration:480/903 loss: 0.6257780194282532\n",
      "Iteration:540/903 loss: 0.7009821534156799\n",
      "Iteration:600/903 loss: 0.6390631794929504\n",
      "Iteration:660/903 loss: 0.7216250896453857\n",
      "Iteration:720/903 loss: 0.704325258731842\n",
      "Iteration:780/903 loss: 0.7114463448524475\n",
      "Iteration:840/903 loss: 0.7227805852890015\n",
      "Iteration:900/903 loss: 0.619522750377655\n",
      "Validation loss after 0 epoch: 0.6805010329352484\n",
      "Accuracy: 0.8660901791229154\n",
      "New best model saved.\n",
      "Epoch: 1\n",
      "64966\n",
      "Iteration:0/903 loss: 0.7116522789001465\n",
      "Iteration:60/903 loss: 0.6932767033576965\n",
      "Iteration:120/903 loss: 0.6870640516281128\n",
      "Iteration:180/903 loss: 0.6446478962898254\n",
      "Iteration:240/903 loss: 0.6463872790336609\n",
      "Iteration:300/903 loss: 0.6360380053520203\n",
      "Iteration:360/903 loss: 0.6625095009803772\n",
      "Iteration:420/903 loss: 0.6631527543067932\n",
      "Iteration:480/903 loss: 0.6636409759521484\n",
      "Iteration:540/903 loss: 0.6826751232147217\n",
      "Iteration:600/903 loss: 0.6627342104911804\n",
      "Iteration:660/903 loss: 0.6743689179420471\n",
      "Iteration:720/903 loss: 0.7397688627243042\n",
      "Iteration:780/903 loss: 0.6680396199226379\n",
      "Iteration:840/903 loss: 0.6212640404701233\n",
      "Iteration:900/903 loss: 0.6360702514648438\n",
      "Validation loss after 1 epoch: 0.6554112209214105\n",
      "Accuracy: 0.892402717726992\n",
      "New best model saved.\n",
      "Epoch: 2\n",
      "64966\n",
      "Iteration:0/903 loss: 0.5954979062080383\n",
      "Iteration:60/903 loss: 0.6201431751251221\n",
      "Iteration:120/903 loss: 0.6050796508789062\n",
      "Iteration:180/903 loss: 0.6608410477638245\n",
      "Iteration:240/903 loss: 0.6729041337966919\n",
      "Iteration:300/903 loss: 0.647783100605011\n",
      "Iteration:360/903 loss: 0.6599679589271545\n",
      "Iteration:420/903 loss: 0.6683062314987183\n",
      "Iteration:480/903 loss: 0.6224344372749329\n",
      "Iteration:540/903 loss: 0.6221546530723572\n",
      "Iteration:600/903 loss: 0.6164789199829102\n",
      "Iteration:660/903 loss: 0.6288443803787231\n",
      "Iteration:720/903 loss: 0.6394991278648376\n",
      "Iteration:780/903 loss: 0.6715771555900574\n",
      "Iteration:840/903 loss: 0.6196680068969727\n",
      "Iteration:900/903 loss: 0.6484277248382568\n",
      "Validation loss after 2 epoch: 0.6513620932896932\n",
      "Accuracy: 0.8965410747374922\n",
      "New best model saved.\n",
      "Epoch: 3\n",
      "64966\n",
      "Iteration:0/903 loss: 0.6225193738937378\n",
      "Iteration:60/903 loss: 0.6256507635116577\n",
      "Iteration:120/903 loss: 0.6554760932922363\n",
      "Iteration:180/903 loss: 0.5865073204040527\n",
      "Iteration:240/903 loss: 0.6481710076332092\n",
      "Iteration:300/903 loss: 0.6903114914894104\n",
      "Iteration:360/903 loss: 0.5965908765792847\n",
      "Iteration:420/903 loss: 0.614450216293335\n",
      "Iteration:480/903 loss: 0.6826046705245972\n",
      "Iteration:540/903 loss: 0.6417405605316162\n",
      "Iteration:600/903 loss: 0.5812446475028992\n",
      "Iteration:660/903 loss: 0.6090555191040039\n",
      "Iteration:720/903 loss: 0.6434743404388428\n",
      "Iteration:780/903 loss: 0.6138275861740112\n",
      "Iteration:840/903 loss: 0.5928802490234375\n",
      "Iteration:900/903 loss: 0.5802266597747803\n",
      "Validation loss after 3 epoch: 0.6447362844149271\n",
      "Accuracy: 0.9041383570105003\n",
      "New best model saved.\n",
      "Epoch: 4\n",
      "64966\n",
      "Iteration:0/903 loss: 0.6476916074752808\n",
      "Iteration:60/903 loss: 0.6249492764472961\n",
      "Iteration:120/903 loss: 0.6356762051582336\n",
      "Iteration:180/903 loss: 0.5726476311683655\n",
      "Iteration:240/903 loss: 0.6485922932624817\n",
      "Iteration:300/903 loss: 0.6009620428085327\n",
      "Iteration:360/903 loss: 0.6423155665397644\n",
      "Iteration:420/903 loss: 0.6156586408615112\n",
      "Iteration:480/903 loss: 0.5953692197799683\n",
      "Iteration:540/903 loss: 0.5547304153442383\n",
      "Iteration:600/903 loss: 0.5685932636260986\n",
      "Iteration:660/903 loss: 0.5795114636421204\n",
      "Iteration:720/903 loss: 0.6129004955291748\n",
      "Iteration:780/903 loss: 0.5983870625495911\n",
      "Iteration:840/903 loss: 0.5935518145561218\n",
      "Iteration:900/903 loss: 0.6631166338920593\n",
      "Validation loss after 4 epoch: 0.6419121800528632\n",
      "Accuracy: 0.9082149474984559\n",
      "New best model saved.\n",
      "Epoch: 5\n",
      "64966\n",
      "Iteration:0/903 loss: 0.5739836692810059\n",
      "Iteration:60/903 loss: 0.6127925515174866\n",
      "Iteration:120/903 loss: 0.5880532264709473\n",
      "Iteration:180/903 loss: 0.6296545267105103\n",
      "Iteration:240/903 loss: 0.6131607890129089\n",
      "Iteration:300/903 loss: 0.5581868886947632\n",
      "Iteration:360/903 loss: 0.6005713939666748\n",
      "Iteration:420/903 loss: 0.6033923029899597\n",
      "Iteration:480/903 loss: 0.6181145310401917\n",
      "Iteration:540/903 loss: 0.592837929725647\n",
      "Iteration:600/903 loss: 0.6186903119087219\n",
      "Iteration:660/903 loss: 0.6052384972572327\n",
      "Iteration:720/903 loss: 0.616197407245636\n",
      "Iteration:780/903 loss: 0.6410883069038391\n",
      "Iteration:840/903 loss: 0.5750863552093506\n",
      "Iteration:900/903 loss: 0.6498926877975464\n",
      "Validation loss after 5 epoch: 0.6443969249725342\n",
      "Accuracy: 0.9043236565781346\n",
      "Epoch: 6\n",
      "64966\n",
      "Iteration:0/903 loss: 0.6030592918395996\n",
      "Iteration:60/903 loss: 0.5872595310211182\n",
      "Iteration:120/903 loss: 0.6060093641281128\n",
      "Iteration:180/903 loss: 0.5811933279037476\n",
      "Iteration:240/903 loss: 0.5954875349998474\n",
      "Iteration:300/903 loss: 0.598784327507019\n",
      "Iteration:360/903 loss: 0.6351717114448547\n",
      "Iteration:420/903 loss: 0.5680868625640869\n",
      "Iteration:480/903 loss: 0.60475754737854\n",
      "Iteration:540/903 loss: 0.6295235753059387\n",
      "Iteration:600/903 loss: 0.5718743801116943\n",
      "Iteration:660/903 loss: 0.6122013330459595\n",
      "Iteration:720/903 loss: 0.624733567237854\n",
      "Iteration:780/903 loss: 0.5773549675941467\n",
      "Iteration:840/903 loss: 0.6208146214485168\n",
      "Iteration:900/903 loss: 0.5954992771148682\n",
      "Validation loss after 6 epoch: 0.6432831671502856\n",
      "Accuracy: 0.9058678196417542\n",
      "Epoch: 7\n",
      "64966\n",
      "Iteration:0/903 loss: 0.5772799849510193\n",
      "Iteration:60/903 loss: 0.5831658840179443\n",
      "Iteration:120/903 loss: 0.5812652111053467\n",
      "Iteration:180/903 loss: 0.5785917639732361\n",
      "Iteration:240/903 loss: 0.5998492240905762\n",
      "Iteration:300/903 loss: 0.5678408741950989\n",
      "Iteration:360/903 loss: 0.6204593777656555\n",
      "Iteration:420/903 loss: 0.6065675616264343\n",
      "Iteration:480/903 loss: 0.6028193831443787\n",
      "Iteration:540/903 loss: 0.5761178135871887\n",
      "Iteration:600/903 loss: 0.5891744494438171\n",
      "Iteration:660/903 loss: 0.5924023389816284\n",
      "Iteration:720/903 loss: 0.5804596543312073\n",
      "Iteration:780/903 loss: 0.6063706874847412\n",
      "Iteration:840/903 loss: 0.6075224280357361\n",
      "Iteration:900/903 loss: 0.5655450820922852\n",
      "Validation loss after 7 epoch: 0.6410036338700189\n",
      "Accuracy: 0.9085237801111797\n",
      "New best model saved.\n",
      "Epoch: 8\n",
      "64966\n",
      "Iteration:0/903 loss: 0.59797203540802\n",
      "Iteration:60/903 loss: 0.5783674716949463\n",
      "Iteration:120/903 loss: 0.6252315044403076\n",
      "Iteration:180/903 loss: 0.5745823383331299\n",
      "Iteration:240/903 loss: 0.593553364276886\n",
      "Iteration:300/903 loss: 0.6010770797729492\n",
      "Iteration:360/903 loss: 0.6170498132705688\n",
      "Iteration:420/903 loss: 0.5682280659675598\n",
      "Iteration:480/903 loss: 0.6045032143592834\n",
      "Iteration:540/903 loss: 0.5793183445930481\n",
      "Iteration:600/903 loss: 0.5703588128089905\n",
      "Iteration:660/903 loss: 0.5671655535697937\n",
      "Iteration:720/903 loss: 0.5708867907524109\n",
      "Iteration:780/903 loss: 0.5627490282058716\n",
      "Iteration:840/903 loss: 0.5965550541877747\n",
      "Iteration:900/903 loss: 0.6026140451431274\n",
      "Validation loss after 8 epoch: 0.6395374578899807\n",
      "Accuracy: 0.9097591105620754\n",
      "New best model saved.\n",
      "Epoch: 9\n",
      "64966\n",
      "Iteration:0/903 loss: 0.5805074572563171\n",
      "Iteration:60/903 loss: 0.5599333047866821\n",
      "Iteration:120/903 loss: 0.5916405916213989\n",
      "Iteration:180/903 loss: 0.5959235429763794\n",
      "Iteration:240/903 loss: 0.5822116732597351\n",
      "Iteration:300/903 loss: 0.5781002640724182\n",
      "Iteration:360/903 loss: 0.5771136283874512\n",
      "Iteration:420/903 loss: 0.5969022512435913\n",
      "Iteration:480/903 loss: 0.5788426399230957\n",
      "Iteration:540/903 loss: 0.5782817602157593\n",
      "Iteration:600/903 loss: 0.5757972002029419\n",
      "Iteration:660/903 loss: 0.5519330501556396\n",
      "Iteration:720/903 loss: 0.5800673365592957\n",
      "Iteration:780/903 loss: 0.5929111838340759\n",
      "Iteration:840/903 loss: 0.5957128405570984\n",
      "Iteration:900/903 loss: 0.5907554626464844\n",
      "Validation loss after 9 epoch: 0.6394191368420918\n",
      "Accuracy: 0.9108709079678814\n",
      "New best model saved.\n",
      "Epoch: 10\n",
      "64966\n",
      "Iteration:0/903 loss: 0.5873052477836609\n",
      "Iteration:60/903 loss: 0.5802306532859802\n",
      "Iteration:120/903 loss: 0.5654181838035583\n",
      "Iteration:180/903 loss: 0.5729739665985107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:240/903 loss: 0.5652458667755127\n",
      "Iteration:300/903 loss: 0.5525014400482178\n",
      "Iteration:360/903 loss: 0.5691633820533752\n",
      "Iteration:420/903 loss: 0.5654361844062805\n",
      "Iteration:480/903 loss: 0.5896544456481934\n",
      "Iteration:540/903 loss: 0.6049467921257019\n",
      "Iteration:600/903 loss: 0.5721753239631653\n",
      "Iteration:660/903 loss: 0.578392744064331\n",
      "Iteration:720/903 loss: 0.5653485655784607\n",
      "Iteration:780/903 loss: 0.5955420136451721\n",
      "Iteration:840/903 loss: 0.6199498772621155\n",
      "Iteration:900/903 loss: 0.577678918838501\n",
      "Validation loss after 10 epoch: 0.6391105813450283\n",
      "Accuracy: 0.9111179740580605\n",
      "New best model saved.\n",
      "Epoch: 11\n",
      "64966\n",
      "Iteration:0/903 loss: 0.5676463842391968\n",
      "Iteration:60/903 loss: 0.5722043514251709\n",
      "Iteration:120/903 loss: 0.5764386653900146\n",
      "Iteration:180/903 loss: 0.5967780351638794\n",
      "Iteration:240/903 loss: 0.579742431640625\n",
      "Iteration:300/903 loss: 0.5953176021575928\n",
      "Iteration:360/903 loss: 0.6182164549827576\n",
      "Iteration:420/903 loss: 0.577894389629364\n",
      "Iteration:480/903 loss: 0.6201894879341125\n",
      "Iteration:540/903 loss: 0.5920669436454773\n",
      "Iteration:600/903 loss: 0.6246741414070129\n",
      "Iteration:660/903 loss: 0.5648133754730225\n",
      "Iteration:720/903 loss: 0.5794634819030762\n",
      "Iteration:780/903 loss: 0.6079621911048889\n",
      "Iteration:840/903 loss: 0.5832898616790771\n",
      "Iteration:900/903 loss: 0.590379536151886\n",
      "Validation loss after 11 epoch: 0.6407992185486687\n",
      "Accuracy: 0.9085855466337245\n",
      "Epoch: 12\n",
      "64966\n",
      "Iteration:0/903 loss: 0.5516115427017212\n",
      "Iteration:60/903 loss: 0.5644466280937195\n",
      "Iteration:120/903 loss: 0.5650655031204224\n",
      "Iteration:180/903 loss: 0.5918731093406677\n",
      "Iteration:240/903 loss: 0.5869848132133484\n",
      "Iteration:300/903 loss: 0.5803406834602356\n",
      "Iteration:360/903 loss: 0.5554081797599792\n",
      "Iteration:420/903 loss: 0.592235803604126\n",
      "Iteration:480/903 loss: 0.5514795780181885\n",
      "Iteration:540/903 loss: 0.5801799893379211\n",
      "Iteration:600/903 loss: 0.5699345469474792\n",
      "Iteration:660/903 loss: 0.5650568604469299\n",
      "Iteration:720/903 loss: 0.5653948783874512\n",
      "Iteration:780/903 loss: 0.6094263195991516\n",
      "Iteration:840/903 loss: 0.5662356019020081\n",
      "Iteration:900/903 loss: 0.5803148150444031\n",
      "Validation loss after 12 epoch: 0.6373262251747979\n",
      "Accuracy: 0.9126003705991352\n",
      "New best model saved.\n",
      "Epoch: 13\n",
      "64966\n",
      "Iteration:0/903 loss: 0.6063683032989502\n",
      "Iteration:60/903 loss: 0.5925338268280029\n",
      "Iteration:120/903 loss: 0.5963744521141052\n",
      "Iteration:180/903 loss: 0.5654769539833069\n",
      "Iteration:240/903 loss: 0.5665748119354248\n",
      "Iteration:300/903 loss: 0.5653463006019592\n",
      "Iteration:360/903 loss: 0.569905698299408\n",
      "Iteration:420/903 loss: 0.5544769167900085\n",
      "Iteration:480/903 loss: 0.5653756260871887\n",
      "Iteration:540/903 loss: 0.5649591088294983\n",
      "Iteration:600/903 loss: 0.6056622266769409\n",
      "Iteration:660/903 loss: 0.5839368104934692\n",
      "Iteration:720/903 loss: 0.6172199249267578\n",
      "Iteration:780/903 loss: 0.5767197012901306\n",
      "Iteration:840/903 loss: 0.5624793767929077\n",
      "Iteration:900/903 loss: 0.5713096857070923\n",
      "Validation loss after 13 epoch: 0.6369272157880995\n",
      "Accuracy: 0.9131562693020383\n",
      "New best model saved.\n",
      "Epoch: 14\n",
      "64966\n",
      "Iteration:0/903 loss: 0.5931865572929382\n",
      "Iteration:60/903 loss: 0.602481484413147\n",
      "Iteration:120/903 loss: 0.5558488965034485\n",
      "Iteration:180/903 loss: 0.5815274119377136\n",
      "Iteration:240/903 loss: 0.5516337752342224\n",
      "Iteration:300/903 loss: 0.5895295143127441\n",
      "Iteration:360/903 loss: 0.5637984275817871\n",
      "Iteration:420/903 loss: 0.5766340494155884\n",
      "Iteration:480/903 loss: 0.5749292969703674\n",
      "Iteration:540/903 loss: 0.6046571135520935\n",
      "Iteration:600/903 loss: 0.5793471932411194\n",
      "Iteration:660/903 loss: 0.5725792050361633\n",
      "Iteration:720/903 loss: 0.5684340000152588\n",
      "Iteration:780/903 loss: 0.5969427227973938\n",
      "Iteration:840/903 loss: 0.5782360434532166\n",
      "Iteration:900/903 loss: 0.5879122614860535\n",
      "Validation loss after 14 epoch: 0.6354126138157314\n",
      "Accuracy: 0.9139592340951205\n",
      "New best model saved.\n",
      "Epoch: 15\n",
      "64966\n",
      "Iteration:0/903 loss: 0.6068087816238403\n",
      "Iteration:60/903 loss: 0.5766890048980713\n",
      "Iteration:120/903 loss: 0.6218196749687195\n",
      "Iteration:180/903 loss: 0.5653456449508667\n",
      "Iteration:240/903 loss: 0.5746341347694397\n",
      "Iteration:300/903 loss: 0.6124440431594849\n",
      "Iteration:360/903 loss: 0.6065869927406311\n",
      "Iteration:420/903 loss: 0.568439245223999\n",
      "Iteration:480/903 loss: 0.5522974729537964\n",
      "Iteration:540/903 loss: 0.5635039806365967\n",
      "Iteration:600/903 loss: 0.5787643790245056\n",
      "Iteration:660/903 loss: 0.5906649231910706\n",
      "Iteration:720/903 loss: 0.5767800211906433\n",
      "Iteration:780/903 loss: 0.6055834889411926\n",
      "Iteration:840/903 loss: 0.591507613658905\n",
      "Iteration:900/903 loss: 0.5628002285957336\n",
      "Validation loss after 15 epoch: 0.6372537978490194\n",
      "Accuracy: 0.9123533045089561\n",
      "Epoch: 16\n",
      "64966\n",
      "Iteration:0/903 loss: 0.5526319146156311\n",
      "Iteration:60/903 loss: 0.5514691472053528\n",
      "Iteration:120/903 loss: 0.5659521818161011\n",
      "Iteration:180/903 loss: 0.5658774375915527\n",
      "Iteration:240/903 loss: 0.5835646986961365\n",
      "Iteration:300/903 loss: 0.5963428020477295\n",
      "Iteration:360/903 loss: 0.6463409662246704\n",
      "Iteration:420/903 loss: 0.5793842673301697\n",
      "Iteration:480/903 loss: 0.5784154534339905\n",
      "Iteration:540/903 loss: 0.593117892742157\n",
      "Iteration:600/903 loss: 0.6317145824432373\n",
      "Iteration:660/903 loss: 0.5654113292694092\n",
      "Iteration:720/903 loss: 0.6095583438873291\n",
      "Iteration:780/903 loss: 0.6005738377571106\n",
      "Iteration:840/903 loss: 0.5775119066238403\n",
      "Iteration:900/903 loss: 0.5656793117523193\n",
      "Validation loss after 16 epoch: 0.6358260949452718\n",
      "Accuracy: 0.9137739345274861\n",
      "Epoch: 17\n",
      "64966\n",
      "Iteration:0/903 loss: 0.5816580057144165\n",
      "Iteration:60/903 loss: 0.5554084181785583\n",
      "Iteration:120/903 loss: 0.5578256845474243\n",
      "Iteration:180/903 loss: 0.5682715773582458\n",
      "Iteration:240/903 loss: 0.593339204788208\n",
      "Iteration:300/903 loss: 0.5653954148292542\n",
      "Iteration:360/903 loss: 0.5937421917915344\n",
      "Iteration:420/903 loss: 0.6182548403739929\n",
      "Iteration:480/903 loss: 0.6180855631828308\n",
      "Iteration:540/903 loss: 0.5802172422409058\n",
      "Iteration:600/903 loss: 0.6079586148262024\n",
      "Iteration:660/903 loss: 0.5785051584243774\n",
      "Iteration:720/903 loss: 0.6126543879508972\n",
      "Iteration:780/903 loss: 0.6066020131111145\n",
      "Iteration:840/903 loss: 0.5708719491958618\n",
      "Iteration:900/903 loss: 0.58121657371521\n",
      "Validation loss after 17 epoch: 0.6371908561388652\n",
      "Accuracy: 0.9127856701667696\n",
      "Epoch: 18\n",
      "64966\n",
      "Iteration:0/903 loss: 0.5725035071372986\n",
      "Iteration:60/903 loss: 0.5655456185340881\n",
      "Iteration:120/903 loss: 0.5792526602745056\n",
      "Iteration:180/903 loss: 0.5619072914123535\n",
      "Iteration:240/903 loss: 0.5907328724861145\n",
      "Iteration:300/903 loss: 0.5660498142242432\n",
      "Iteration:360/903 loss: 0.5670945644378662\n",
      "Iteration:420/903 loss: 0.5515627264976501\n",
      "Iteration:480/903 loss: 0.5803597569465637\n",
      "Iteration:540/903 loss: 0.5666978359222412\n",
      "Iteration:600/903 loss: 0.551463782787323\n",
      "Iteration:660/903 loss: 0.5978577136993408\n",
      "Iteration:720/903 loss: 0.5645796060562134\n",
      "Iteration:780/903 loss: 0.5516926050186157\n",
      "Iteration:840/903 loss: 0.5872530341148376\n",
      "Iteration:900/903 loss: 0.5785570740699768\n",
      "Validation loss after 18 epoch: 0.6406246248881022\n",
      "Accuracy: 0.9099444101297097\n",
      "Epoch: 19\n",
      "64966\n",
      "Iteration:0/903 loss: 0.5515389442443848\n",
      "Iteration:60/903 loss: 0.5918054580688477\n",
      "Iteration:120/903 loss: 0.5874858498573303\n",
      "Iteration:180/903 loss: 0.6188461184501648\n",
      "Iteration:240/903 loss: 0.6052497029304504\n",
      "Iteration:300/903 loss: 0.590534508228302\n",
      "Iteration:360/903 loss: 0.5928221940994263\n",
      "Iteration:420/903 loss: 0.5651817321777344\n",
      "Iteration:480/903 loss: 0.5641451478004456\n",
      "Iteration:540/903 loss: 0.566987156867981\n",
      "Iteration:600/903 loss: 0.5786397457122803\n",
      "Iteration:660/903 loss: 0.5649844408035278\n",
      "Iteration:720/903 loss: 0.5837604999542236\n",
      "Iteration:780/903 loss: 0.5826388001441956\n",
      "Iteration:840/903 loss: 0.5515725016593933\n",
      "Iteration:900/903 loss: 0.5671845078468323\n",
      "Validation loss after 19 epoch: 0.6369531358612909\n",
      "Accuracy: 0.913218035824583\n",
      "Epoch: 20\n",
      "64966\n",
      "Iteration:0/903 loss: 0.5516294836997986\n",
      "Iteration:60/903 loss: 0.6007668972015381\n",
      "Iteration:120/903 loss: 0.5755420923233032\n",
      "Iteration:180/903 loss: 0.5514695644378662\n",
      "Iteration:240/903 loss: 0.5929043292999268\n",
      "Iteration:300/903 loss: 0.565345048904419\n",
      "Iteration:360/903 loss: 0.5653555393218994\n",
      "Iteration:420/903 loss: 0.5747287273406982\n",
      "Iteration:480/903 loss: 0.5780116319656372\n",
      "Iteration:540/903 loss: 0.5582454800605774\n",
      "Iteration:600/903 loss: 0.5922637581825256\n",
      "Iteration:660/903 loss: 0.5801980495452881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:720/903 loss: 0.579704999923706\n",
      "Iteration:780/903 loss: 0.5802895426750183\n",
      "Iteration:840/903 loss: 0.5519291162490845\n",
      "Iteration:900/903 loss: 0.6093069314956665\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 72\n",
    "# Get the training data len\n",
    "batches = batchify(df_train, batch_size)\n",
    "length = sum(1 for x in batches)\n",
    "# Model folder name\n",
    "experiment = \"lstm\"\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    if epoch == 0:\n",
    "        validate(net, df_test, batch_size, epoch)\n",
    "    net.train()\n",
    "    \n",
    "    # Shuffle and batchify the data\n",
    "    shuffled_df = shuffle_df(df_train)\n",
    "    print(len(shuffled_df))\n",
    "    counter = 0\n",
    "    batches = batchify(shuffled_df, batch_size)\n",
    "    \n",
    "    for df_batch in batches:\n",
    "        \n",
    "        inp = create_input_batch(df_batch)\n",
    "        labels = torch.Tensor(df_batch['y'].values).to(device).long()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = net(inp)\n",
    "\n",
    "        batch_loss = criterion(output['out'], labels)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        # Some informative output\n",
    "        if(counter % 60 == 0):\n",
    "            print(f\"Iteration:{counter}/{length} loss: {batch_loss.item()}\")\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "    _, accuracy = validate(net, df_test, batch_size, epoch)\n",
    "    # No early stopping needed, as only the best model is saved.\n",
    "    saved = save_best_model(net, experiment, accuracy)\n",
    "    if saved:\n",
    "        print(f\"New best model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
